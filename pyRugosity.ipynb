{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topographic Complexity/Variability: Rugosity  \n",
    "Developed in November 2023 by Dr. Larry Syu-Heng Lai (University of Washington)  \n",
    "\n",
    "Recommended reference:\n",
    "* Wilson, M.F.J., O’Connell, B., Brown, C., Guinan, J.C., Grehan, A.J., 2007. Multiscale Terrain Analysis of Multibeam Bathymetry Data for Habitat Mapping on the Continental Slope. Marine Geodesy 30, 3-35. https://doi.org/10.1080/01490410701295962 \n",
    "* Du Preez, C. A new arc–chord ratio (ACR) rugosity index for quantifying three-dimensional landscape structural complexity. Landscape Ecol 30, 181–192 (2015). https://doi.org/10.1007/s10980-014-0118-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import joblib\n",
    "from scipy.linalg import lstsq\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your file paths and file names separately\n",
    "input_folder = '/Users/larryslai/Library/CloudStorage/Dropbox/QGIS/WA LiDAR/'\n",
    "#input_file_name = 'Test_DEM.tif'\n",
    "input_file_name = 'Tokeland_DEM.tif'\n",
    "#input_file_name = 'Nemah_DEM.tif'\n",
    "#input_file_name = 'Francies_DEM.tif'\n",
    "\n",
    "output_folder = '/Users/larryslai/Library/CloudStorage/Dropbox/QGIS/WA LiDAR/'\n",
    "#output_file_name = 'Test_pyRugosity.tif'\n",
    "output_file_name = 'Tokeland_pyRugosity.tif'\n",
    "#output_file_name = 'Nemah_pyRugosity.tif'\n",
    "#output_file_name = 'Francies_pyRugosity.tif'\n",
    "\n",
    "# Combine folder and file names to create the full paths\n",
    "input_tif_path = input_folder + input_file_name\n",
    "output_tif_path = output_folder + output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(input_tif_path) as src:\n",
    "    dem = src.read(1)  # Read the first band into a 2D array\n",
    "    meta = src.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See coordinate system info of the GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS: PROJCS[\"NAD83(HARN) / Washington South (ftUS)\",GEOGCS[\"NAD83(HARN)\",DATUM[\"North_American_1983_HARN\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",45.3333333333333],PARAMETER[\"central_meridian\",-120.5],PARAMETER[\"standard_parallel_1\",45.8333333333333],PARAMETER[\"standard_parallel_2\",47.3333333333333],PARAMETER[\"false_easting\",1640416.66666667],PARAMETER[\"false_northing\",0],UNIT[\"US survey foot\",0.304800609601219,AUTHORITY[\"EPSG\",\"9003\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n",
      "CRS as WKT: PROJCS[\"NAD83(HARN) / Washington South (ftUS)\",GEOGCS[\"NAD83(HARN)\",DATUM[\"North_American_1983_HARN\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",45.3333333333333],PARAMETER[\"central_meridian\",-120.5],PARAMETER[\"standard_parallel_1\",45.8333333333333],PARAMETER[\"standard_parallel_2\",47.3333333333333],PARAMETER[\"false_easting\",1640416.66666667],PARAMETER[\"false_northing\",0],UNIT[\"US survey foot\",0.304800609601219,AUTHORITY[\"EPSG\",\"9003\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n",
      "CRS as PROJ string: +proj=lcc +lat_0=45.3333333333333 +lon_0=-120.5 +lat_1=45.8333333333333 +lat_2=47.3333333333333 +x_0=500000.000000001 +y_0=0 +ellps=GRS80 +units=us-ft +no_defs=True\n",
      "CRS as EPSG code: None\n",
      "CRS as dictionary: {'proj': 'lcc', 'lat_0': 45.3333333333333, 'lon_0': -120.5, 'lat_1': 45.8333333333333, 'lat_2': 47.3333333333333, 'x_0': 500000.000000001, 'y_0': 0, 'ellps': 'GRS80', 'units': 'us-ft', 'no_defs': True}\n"
     ]
    }
   ],
   "source": [
    "# Open the GeoTIFF file\n",
    "with rasterio.open(input_tif_path) as src:\n",
    "    # Read the CRS\n",
    "    crs = src.crs\n",
    "    \n",
    "    # Print the CRS information\n",
    "    print(f\"CRS: {crs}\")\n",
    "    print(f\"CRS as WKT: {crs.wkt}\")\n",
    "    print(f\"CRS as PROJ string: {crs.to_proj4()}\")\n",
    "    print(f\"CRS as EPSG code: {crs.to_epsg()}\")\n",
    "    print(f\"CRS as dictionary: {crs.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rugosity (slope-corrected)\n",
    "\n",
    "Rugosity measures the complexity of the surface texture and is defined as the ratio of the actual surface area to the planar area. It is calculated using a $N \\times N$ neighborhood around each pixel:\n",
    "\n",
    "$$\n",
    "\\text{Rugosity Index} = \\frac{\\text{surface area of NxN neighborhood}}{\\text{planar area of NxN neighborhood}}\n",
    "$$\n",
    "\n",
    ", where $N$ is the window size. In practice, the surface area is estimated using the gradients of the elevation within the neighborhood, accounting for the additional area contributed by the terrain's slope.  \n",
    "\n",
    "The planer area should be the area of the surface orthogonally projected onto a plane of best fit within the window. To calculate the planar area as the area of the surface orthogonally projected onto a plane of best fit within the window, we need to compute the local slope and aspect for each cell within the window, and then use these to project the area onto the best-fit plane. After this local slope correction, the result is the indext so-called arc-chord ratio (ACR) rugosity index. See details in Du Preez (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rugosity functions (optimized with chunk processing and parallel processing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_plane_to_window(window):\n",
    "    \"\"\"\n",
    "    Fit a plane to a window of elevation data.\n",
    "\n",
    "    :param window: 2D array of elevation values.\n",
    "    :return: Coefficients of the plane.\n",
    "    \"\"\"\n",
    "    window_size = window.shape[0]\n",
    "    x, y = np.indices(window.shape)\n",
    "    A = np.c_[x.ravel(), y.ravel(), np.ones(window.size)]\n",
    "    C, _, _, _ = lstsq(A, window.ravel())  # Coefficients of the plane\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_orthogonal_projected_area(window, coeffs):\n",
    "    \"\"\"\n",
    "    Calculate the area of the surface orthogonally projected onto a plane of best fit.\n",
    "\n",
    "    :param window: 2D array of elevation values.\n",
    "    :param coeffs: Coefficients of the plane.\n",
    "    :return: Projected area of the surface.\n",
    "    \"\"\"\n",
    "    # Calculate normal vector to the plane\n",
    "    nx, ny, nz = coeffs[0], coeffs[1], -1\n",
    "    normal = np.array([nx, ny, nz])\n",
    "    normal_length = np.linalg.norm(normal)\n",
    "    \n",
    "    # Calculate area of the projected plane\n",
    "    window_size = window.shape[0]\n",
    "    projected_area = window_size**2 / normal_length\n",
    "    return projected_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rugosity_chunk(dem, window_size, i, j, chunk_size, overlap):\n",
    "    \"\"\"\n",
    "    Calculate rugosity for a chunk of the raster, considering an overlap to avoid edge artifacts.\n",
    "    \n",
    "    :param dem: 2D array of elevation values for the entire raster.\n",
    "    :param window_size: Size of the moving window to calculate rugosity.\n",
    "    :param i: Starting row index for the chunk.\n",
    "    :param j: Starting column index for the chunk.\n",
    "    :param chunk_size: Size of the chunks to divide the raster for parallel processing.\n",
    "    :param overlap: Width of the overlap area around each chunk.\n",
    "    :return: 2D array of rugosity values for the chunk.\n",
    "    \"\"\"\n",
    "    # Define the extended chunk indices with overlap\n",
    "    start_i = max(i - overlap, 0)\n",
    "    end_i = min(i + chunk_size + overlap, dem.shape[0])\n",
    "    start_j = max(j - overlap, 0)\n",
    "    end_j = min(j + chunk_size + overlap, dem.shape[1])\n",
    "    \n",
    "    # Extract the extended chunk from the DEM\n",
    "    chunk = dem[start_i:end_i, start_j:end_j]\n",
    "    \n",
    "    # Calculate rugosity for the extended chunk\n",
    "    rugosity_chunk = np.zeros((end_i - start_i, end_j - start_j), dtype=np.float32)\n",
    "    for row in range(overlap, end_i - start_i - overlap):\n",
    "        for col in range(overlap, end_j - start_j - overlap):\n",
    "            window = chunk[row - overlap:row + overlap + 1, col - overlap:col + overlap + 1]\n",
    "            coeffs = fit_plane_to_window(window)\n",
    "            projected_area = calculate_orthogonal_projected_area(window, coeffs)\n",
    "            surface_area = np.sum(np.sqrt(1 + np.gradient(window)[0]**2 + np.gradient(window)[1]**2))\n",
    "            rugosity_chunk[row, col] = surface_area / projected_area\n",
    "    \n",
    "    # Return the non-overlapping part of the chunk\n",
    "    return rugosity_chunk[overlap:-overlap, overlap:-overlap], (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rugosity_parallel(dem, window_size, chunk_size):\n",
    "    \"\"\"\n",
    "    Compute rugosity for the raster using parallel processing with chunk-based approach.\n",
    "    \n",
    "    :param dem: 2D array of elevation values.\n",
    "    :param window_size: Size of the moving window to calculate rugosity.\n",
    "    :param chunk_size: Size of the chunks to divide the raster for parallel processing.\n",
    "    :return: 2D array of rugosity values.\n",
    "    \"\"\"\n",
    "    rows, cols = dem.shape\n",
    "    overlap = window_size // 2  # Set the overlap width to half of the window size\n",
    "    rugosity_map = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "    # Define chunk indices for parallel processing\n",
    "    chunk_indices = [(i, j)\n",
    "                     for i in range(overlap, rows - overlap, chunk_size)\n",
    "                     for j in range(overlap, cols - overlap, chunk_size)]\n",
    "    \n",
    "    # Process chunks in parallel\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "        results = parallel(delayed(calculate_rugosity_chunk)(dem, window_size, i, j, chunk_size, overlap)\n",
    "                           for i, j in tqdm(chunk_indices, desc='Computing Rugosity'))\n",
    "\n",
    "    # Stitch the results together\n",
    "    for (rugosity_chunk, (i, j)) in results:\n",
    "        # Compute the correct slice size for the rugosity map\n",
    "        slice_size_i = rugosity_chunk.shape[0]\n",
    "        slice_size_j = rugosity_chunk.shape[1]\n",
    "        rugosity_map[i:i + slice_size_i, j:j + slice_size_j] = rugosity_chunk\n",
    "\n",
    "    return rugosity_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Rugosity with a given window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda826cbd4b34475b4942b10a1f6cdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing Rugosity:   0%|          | 0/2538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate rugosity for the entire DEM with a specified window size\n",
    "window_size = 3  # N x N neighborhood\n",
    "chunk_size = 512  # Example chunk size, adjust based on your system's memory capacity\n",
    "\n",
    "# Compute rugosity with parallel processing and chunk-based approach\n",
    "rugosity_map = compute_rugosity_parallel(dem, window_size, chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output data into GeoTIFF\n",
    "* Enabling geotiff compression to reduce writing time\n",
    "* Enabling Tile-based writing if needed\n",
    "* Enabling BIGTIFF parameter to allow writing a large GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata for output GeoTIFF\n",
    "meta.update(dtype=rasterio.float32, compress='lzw', tiled=True, bigtiff='IF_SAFER')\n",
    "\n",
    "# Write Rugosity to a new GeoTIFF\n",
    "with rasterio.open(output_tif_path, 'w', **meta) as dst:\n",
    "   dst.write(rugosity_map.astype(rasterio.float32), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
