{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topographic Complexity/Variability: Mexican Hat Wavelet Analysis  \n",
    "* The original MATLAB code was developed by Dr. Adam M. Booth (Portland State Univeristy).  \n",
    "    * Citations:  \n",
    "        * Booth, A.M., Roering, J.J., Perron, J.T., 2009. Automated landslide mapping using spectral analysis and high-resolution topographic data: Puget Sound lowlands, Washington, and Portland    Hills, Oregon. Geomorphology 109, 132-147. https://doi.org/10.1016/j.geomorph.2009.02.027  \n",
    "        * Booth, A.M., LaHusen, S.R., Duvall, A.R., Montgomery, D.R., 2017. Holocene history of deep-seated landsliding in the North Fork Stillaguamish River valley from surface roughness analysis, radiocarbon dating, and numerical landscape evolution modeling. Journal of Geophysical Research: Earth Surface 122, 456-472. https://doi.org/10.1002/2016JF003934  \n",
    "* This MATLAB code was later adapted by Dr. Sean R. LaHusen (Univeristy of Washington) & revised by Erich N. Herzig (Univeristy of Washington).\n",
    "    * Citations:  \n",
    "       * LaHusen, S.R., Duvall, A.R., Booth, A.M., Montgomery, D.R., 2016. Surface roughness dating of long-runout landslides near Oso, Washington (USA), reveals persistent postglacial hillslope instability. Geology 44, 111-114. https://doi.org/10.1130/G37267.1  \n",
    "       * LaHusen, S.R., Duvall, A.R., Booth, A.M., Grant, A., Mishkin, B.A., Montgomery, D.R., Struble, W., Roering, J.J., Wartman, J., 2020. Rainfall triggers more deep-seated landslides than Cascadia earthquakes in the Oregon Coast Range, USA. Science Advances 6, eaba6790. https://doi.org/10.1126/sciadv.aba6790  \n",
    "       * Herzig, E.N., Duvall, A.R., Booth, A.R., Stone, I., Wirth, E., LaHusen, S.R., Wartman, J., Grant, A.; Evidence of Seattle Fault Earthquakes from Patterns in Deep‚ÄêSeated Landslides. Bulletin of the Seismological Society of America 2023; https://doi.org/10.1785/0120230079 \n",
    "* In November, 2023; this is code translated and optimized into this python version by Dr. Larry Syu-Heng Lai (Univeristy of Washington)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "import rasterio\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mexican function using FFT Colvolve\n",
    "\"\"\"\n",
    "    Computes the 2D CWT of dem using the Mexican Hat wavelet. \n",
    "    Optimized using fft\n",
    "    \n",
    "    dem = digital elevation model\n",
    "    a = wavelet scale\n",
    "    dx = grid spacing (same in x- and y-directions)\n",
    "\n",
    "    Returns:\n",
    "    C = array of wavelet coefficients, indexed to dem\n",
    "    frq = bandpass frequency of wavelet at scale a\n",
    "    wave = wavelength (inverse of frq)\n",
    "\"\"\"\n",
    "In this version, masking the artifacts at the edges are conducted during chunk processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2_mexh_fft(dem, a, dx):\n",
    "    # Generate the mexican hat wavelet kernel at wavelet scale a.\n",
    "    # The kernel must be large enough for the wavelet to decay to ~0 at the edges.\n",
    "    X, Y = np.meshgrid(np.arange(-8*a, 8*a+1), np.arange(-8*a, 8*a+1))\n",
    "\n",
    "    # This psi has been scaled, so C is equal to curvature:\n",
    "    psi = (-1/(np.pi*(a*dx)**4)) * (1 - (X**2 + Y**2)/(2*a**2)) * np.exp(-(X**2 + Y**2)/(2*a**2))  # units of [1/(m^4)]\n",
    "\n",
    "    # Convolve dem with psi using scipy's convolve2d function, multiplying by dx^2\n",
    "    # to approximate the double integral. 'same' mode crops C to same size as dem.\n",
    "    C = (dx**2) * fftconvolve(dem*0.3048, psi, mode='same')  # units of [(m^2) x (m) x (1/(m^4)) = (1/m)]\n",
    "\n",
    "    # Frequency and wavelength vectors:\n",
    "    wave = 2*np.pi*dx*a/(5/2)**(1/2)  # Torrence and Compo [1998]\n",
    "    frq = 1./wave\n",
    "\n",
    "    return C, frq, wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for chunk processing (avoid RAM issues for big GeoTIFF)\n",
    "In this current method, the maximum size allowed for imported GeoTIFF is limited by your RAM capacity. Usually files with size <3.7GB would be preferrable in this version. To process much larger GeoTIFFs, please consider using the version 'chunkIC' with incremental writing capability, which ensures worability yet with lower perfermance (longer processing time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_dask(input_dir, output_dir, a, dx, overlap, chunksize=(1024, 1024)):\n",
    "    with rasterio.open(input_dir) as src:\n",
    "        meta = src.meta.copy()\n",
    "        \n",
    "        # Create a Dask array from the raster data\n",
    "        dem = da.from_array(src.read(1), chunksize)  # Adjust chunk size as needed\n",
    "        \n",
    "        # Use map_overlap to apply processing with overlap\n",
    "        processed_data = dem.map_overlap(\n",
    "            lambda block: np.abs(conv2_mexh_fft(block, a, dx)[0]),\n",
    "            depth=overlap,  # Specifies the overlap\n",
    "            boundary='reflect',\n",
    "            trim=True,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    # Setup output metadata\n",
    "    meta.update(dtype=rasterio.float32, count=1, compress='lzw', bigtiff='IF_SAFER')\n",
    "    \n",
    "    with ProgressBar():\n",
    "        with rasterio.open(output_dir, 'w', **meta) as dst:\n",
    "            # Compute the processed data\n",
    "            result = processed_data.compute()\n",
    "            \n",
    "            # Mask edge effects with NaN (no data) values\n",
    "            fringeval = int(np.ceil(a*4))\n",
    "            result[:fringeval, :] = np.nan\n",
    "            result[:, :fringeval] = np.nan\n",
    "            result[-fringeval:, :] = np.nan\n",
    "            result[:, -fringeval:] = np.nan\n",
    "            \n",
    "            # Write result to file, taking into account the dtype\n",
    "            if meta['dtype'] == rasterio.float32:\n",
    "                dst.write(result, 1)\n",
    "            else:\n",
    "                # For non-float data types, need to ensure NaNs are handled properly\n",
    "                # This example assumes float32 output; adjust as needed for other types\n",
    "                raise ValueError(\"Output data type must be float32 to support NaN values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup files directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "base_dir = '.../' #put your own directory\n",
    "#input_dir = os.path.join(base_dir, 'Test_DEM.tif')\n",
    "#output_dir = os.path.join(base_dir, 'Test_pymexhat_chunk.tif')\n",
    "input_dir = os.path.join(base_dir, 'Testbig_DEM.tif')\n",
    "output_dir = os.path.join(base_dir, 'Testbig_pymexhat_chunk.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DEM file\n",
    "with rasterio.open(input_dir) as src:\n",
    "    dem = src.read(1)\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "\n",
    "    # Print the CRS information\n",
    "    print(f\"CRS: {crs}\")\n",
    "    print(f\"CRS as WKT: {crs.wkt}\")\n",
    "    print(f\"CRS as PROJ string: {crs.to_proj4()}\")\n",
    "    print(f\"CRS as EPSG code: {crs.to_epsg()}\")\n",
    "    print(f\"CRS as dictionary: {crs.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 1.8288  # Grid spacing\n",
    "a = 4.1  # Scale of the wavelet\n",
    "\n",
    "# Define overlap size\n",
    "overlap = int(a * 4)  # Example overlap based on wavelet scale 'a'\n",
    "#overlap = 50  # define arbitrary size of overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()  # Start timer\n",
    "\n",
    "chunksize = (1024, 1024) # Adjust the chunk size to best utilize the memory.\n",
    "process_with_dask(input_dir, output_dir, a, dx, overlap, chunksize)\n",
    "\n",
    "end_time = time.time()  # Stop timer\n",
    "print(f\"Execution time: {end_time - start_time:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
