{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pyTopoComplexity (v0.7.3)**\n",
    "### **Example for using `pyfracd` module to perform fractal dimension analysis** \n",
    "\n",
    "Fractal dimension analysis provides a powerful method for characterizing the roughness and complexity of land surfaces using Digital Elevation Model (DEM) data. This approach, as implemented in the `pyfracd` module, offers a quantitative measure of terrain texture at various scales. For each cell in the DEM, the local fractal dimension is calculated using the intersection of the surface within the moving window with four vertical planes corresponding to the principal geographical directions (N-S, E-W, NW-SE, and NE-SW). This reduces the problem to estimating the fractal dimension of one-dimensional topographic profiles. The variogram method is used to estimate the fractal dimension of these profiles. The variogram, a statistical function that estimates the dissimilarity between two random variables separated by a distance, is particularly effective for this purpose. The relationship between the variogram and distance is modeled using a power-law function, from which the fractal dimension can be derived.\n",
    "\n",
    "The pyfracd class implements this methodology, providing not only the local fractal dimension estimates but also reliability parameters such as the standard error of the estimated fractal dimension and the coefficient of determination. These additional metrics help assess the quality and reliability of the fractal dimension estimates across the analyzed terrain.\n",
    "\n",
    "To use this code, please cite the Zenodo repository that hosts the latest release of this code: \n",
    "* Lai, L. S.-H. (2024). pyTopoComplexity. Zenodo. https://doi.org/10.5281/zenodo.11239338\n",
    "* Github repository: https://github.com/GeoLarryLai/pyTopoComlexity\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Theory** (adapted from Pardo-Igúzquiza & Dowd, 2022)\n",
    "\n",
    "The foundation of the fractal dimension calculation is the variogram, a statistical function that estimates the dissimilarity between two random variables separated by a distance. For topographic analysis, the variogram is defined as:\n",
    "\n",
    "$$\\gamma(h) = \\frac{1}{2} E\\{[Z(i + h) - Z(i)]^2\\}$$\n",
    "\n",
    "Here, $\\gamma(h)$ is the variogram for distance $h$, $E\\{\\cdot\\}$ is the mathematical expectation operator, and $Z(i)$ is the random variable describing the altitude at location $i$. The variogram is crucial because it captures the spatial structure of the topography, which is key to understanding its fractal properties.\n",
    "\n",
    "For fractal surfaces, the variogram follows a power-law model:\n",
    "\n",
    "$$\\gamma(h) = \\alpha h^\\beta, \\quad \\alpha \\geq 0; \\quad 0 \\leq \\beta < 2$$\n",
    "\n",
    "The parameters $\\alpha$ and $\\beta$ define the power variogram model. This model is particularly useful because it directly relates to the fractal dimension of the surface. The relationship between the fractal dimension (FD) and $\\beta$ is given by:\n",
    "\n",
    "$$FD = E + 1 - \\frac{\\beta}{2}$$\n",
    "\n",
    "where $E$ is the topological dimension of the Euclidean space. For one-dimensional topographic profiles (where $E = 1$), this simplifies to:\n",
    "\n",
    "$$(FD)_1 = 2 - \\frac{\\beta}{2}$$\n",
    "\n",
    "To estimate the fractal dimension of a two-dimensional surface from these one-dimensional profiles, we use:\n",
    "\n",
    "$$(FD)_2^* = 1 + (FD)_1^*$$\n",
    "\n",
    "This allows us to characterize the roughness of the entire surface based on analyses of multiple one-dimensional profiles.\n",
    "\n",
    "In practice, we estimate the variogram from the DEM data using:\n",
    "\n",
    "$$\\gamma_1(k) = \\frac{1}{2(L-k)} \\sum_{l=1}^{L-k} [z(i) - z(i+l)]^2$$\n",
    "\n",
    "Here, $L$ is the profile length, $k$ is the lag distance, and $z(i)$ is the observed altitude at position $i$. This estimator allows us to calculate the variogram from discrete elevation data.\n",
    "\n",
    "To estimate $\\beta$, which is crucial for determining the fractal dimension, we use the log-log relationship:\n",
    "\n",
    "$$\\ln[\\gamma_1(k)] = \\beta \\ln[k] + \\ln[\\alpha]$$\n",
    "\n",
    "By fitting a line to this log-log plot, we can estimate $\\beta$ from the slope.\n",
    "\n",
    "The local fractal dimension is calculated using a moving window approach. For each pixel $(i,j)$ in the DEM, we consider profiles in four directions. For example, the East-West profile is:\n",
    "\n",
    "$$\\{z(i-W/2,j), z(i-W/2+1,j), \\ldots, z(i-1,j), z(i,j), z(i+1,j), \\ldots, z(i+W/2-1,j), z(i+W/2,j)\\}$$\n",
    "\n",
    "where $W$ is the size of the moving window and $z(i,j)$ is the altitude of pixel $(i,j)$. Similar profiles are extracted for the other three directions.\n",
    "\n",
    "By applying these equations to each pixel in the DEM, we can create a new raster map showing the spatial variability of topographic roughness. This approach allows for a detailed characterization of terrain complexity, revealing patterns and structures that might not be apparent in the original elevation data. The resulting fractal dimension maps provide valuable insights for geomorphological and geological studies, particularly in remote or inaccessible areas like the Martian surface.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References**\n",
    "##### Journal Articles: \n",
    "* Pardo-Igúzquiza, E., Dowd, P.A., 2022. The roughness of martian topography: A metre-scale fractal analysis of six selected areas. Icarus 384, 115109. https://doi.org/10.1016/j.icarus.2022.115109.\n",
    "* Wilson, M.F.J., O’Connell, B., Brown, C., Guinan, J.C., Grehan, A.J., 2007. Multiscale Terrain Analysis of Multibeam Bathymetry Data for Habitat Mapping on the Continental Slope. Marine Geodesy 30, 3-35. https://doi.org/10.1080/01490410701295962 \n",
    "\n",
    "##### Digital Elevation Model (DEM) Examples:\n",
    "* Washington Geological Survey, 2023. 'Stillaguamish 2014' and 'Snohoco Hazel 2006' projects [lidar data]: originally contracted by Washington State Department of Transportation (WSDOT). [accessed April 4, 2024, at http://lidarportal.dnr.wa.gov]\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.getcwd()  # Change the directory of base folder as needed\n",
    "base_dir = os.path.join(base_dir, 'ExampleDEM')\n",
    "input_file = 'Ososlid2014_f_6ftgrid.tif'\n",
    "input_dir = os.path.join(base_dir, input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run fractal dimension analysis\n",
    "\n",
    "**How the Number of Lags Affects Fractal Dimension Estimates**\n",
    "\n",
    "In the pyfracd class, the \"npas\" parameter sets the number of lags (K) used to calculate fractal dimensions. This number is important because it affects how reliable our results are. The number of lags is related to the size of the area we look at (the moving window). A bigger window means we can use more data points, which can make our estimates more reliable. But even if we keep the window size the same, changing the number of lags can still affect our results. Using more lags can give us more accurate results, but it also takes longer for the computer to calculate. So we need to find a balance between accuracy and speed.\n",
    "\n",
    "When using pyfracd, it's a good idea to try different values for \"npas\" to see what works best for your specific data and research questions. The best choice might be different for different situations.\n",
    "\n",
    "- Typically range from 10 to 20.\n",
    "- Consider using multiple `npas` values for different scales\n",
    "- Justify choice based on study objectives and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m fa \u001b[38;5;241m=\u001b[39m pyfracd(npas\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the analysis using pyfrad modeul (with variogram plotting function on)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m Z, fd_result, se_result, r2_result, meta \u001b[38;5;241m=\u001b[39m \u001b[43mfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariograms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/My Documents/University of Washington/(Project) Cascadia Copes Hub/Roughness codes/Github/testpypi/lib/python3.10/site-packages/pytopocomplexity/pyfracd.py:87\u001b[0m, in \u001b[0;36mpyfracd.analyze\u001b[0;34m(self, input_dir, variograms)\u001b[0m\n\u001b[1;32m     85\u001b[0m data \u001b[38;5;241m=\u001b[39m Z[j, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m):\u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m21\u001b[39m, src\u001b[38;5;241m.\u001b[39mwidth)]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpas:\n\u001b[0;32m---> 87\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m data \u001b[38;5;241m=\u001b[39m Z[\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m):\u001b[38;5;28mmin\u001b[39m(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m21\u001b[39m, src\u001b[38;5;241m.\u001b[39mheight), i]\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpas:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytopocomplexity import pyfracd\n",
    "\n",
    "# Create pyfracd instance\n",
    "fa = pyfracd(npas=10)\n",
    "\n",
    "# Run the analysis using pyfrad modeul (with variogram plotting function on)\n",
    "Z, fd_result, se_result, r2_result, meta = fa.analyze(input_dir, variograms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output file name\n",
    "output_fd_file = os.path.splitext(input_file)[0] + '_pyFD.tif'\n",
    "output_fdse_file = os.path.splitext(input_file)[0] + '_pyFDse.tif'\n",
    "output_fdr2_file = os.path.splitext(input_file)[0] + '_pyFDr2.tif'\n",
    "output_fd_dir = os.path.join(base_dir, output_fd_file)\n",
    "output_fdse_dir = os.path.join(base_dir, output_fdse_file)\n",
    "output_fdr2_dir = os.path.join(base_dir, output_fdr2_file)\n",
    "\n",
    "# Export results using pyfracd module\n",
    "fa.export_results(output_fd_dir, output_fdse_dir, output_fdr2_dir, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Display results\n",
    "\n",
    "Products of Fractal Dimension Analysis include:\n",
    "\n",
    "1. **Local Fractal Dimension (FD) Map**: Displays the spatial distribution of fractal dimension values (2-3) across the terrain, with higher values indicating greater surface roughness.\n",
    "\n",
    "2. **Standard Error (SE) Map**: Shows the uncertainty associated with each local FD estimate, with lower values indicating more reliable estimates.\n",
    "\n",
    "3. **Coefficient of Determination (R²) Map**: Indicates how well the power-law model fits the experimental variogram data at each location, with higher values suggesting better fit and more reliable estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "# Get CRS information for plotting\n",
    "with rasterio.open(input_dir) as src:\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "\n",
    "# Plot the hillshade\n",
    "ls = LightSource(azdeg=315, altdeg=45)\n",
    "hillshade = ls.hillshade(Z, vert_exag=2)\n",
    "hs = axes[0, 0].imshow(hillshade, cmap='gray')\n",
    "axes[0, 0].set_title(input_file)\n",
    "axes[0, 0].set_xlabel(f'X-axis grids \\n(grid size ≈ {round(transform[0],4)} [{crs.linear_units}])')\n",
    "axes[0, 0].set_ylabel(f'Y-axis grids \\n(grid size ≈ {-round(transform[4],4)} [{crs.linear_units}])')\n",
    "cbar1 = fig.colorbar(hs, ax=axes[0, 0], orientation='horizontal', fraction=0.045, pad=0.13)\n",
    "cbar1.ax.set_visible(False)\n",
    "\n",
    "# Plot the Fractal Dimension\n",
    "im1 = axes[0, 1].imshow(fd_result, cmap='viridis')\n",
    "im1.set_clim(round(np.nanpercentile(fd_result, 0), 2), round(np.nanpercentile(fd_result, 100), 2))\n",
    "axes[0, 1].set_title('Fractal Dimension')\n",
    "axes[0, 1].set_xlabel(f'X-axis grids \\n(grid size ≈ {round(transform[0],4)} [{crs.linear_units}])')\n",
    "axes[0, 1].set_ylabel(f'Y-axis grids \\n(grid size ≈ {-round(transform[4],4)} [{crs.linear_units}])')\n",
    "cbar2 = fig.colorbar(im1, ax=axes[0, 1], orientation='horizontal', fraction=0.045, pad=0.13)\n",
    "\n",
    "# Plot the Standard Error\n",
    "im2 = axes[1, 0].imshow(se_result, cmap='plasma')\n",
    "im2.set_clim(round(np.nanpercentile(se_result, 0), 2), round(np.nanpercentile(se_result, 100), 2))\n",
    "axes[1, 0].set_title('Standard Error of Fractal Dimension')\n",
    "axes[1, 0].set_xlabel(f'X-axis grids \\n(grid size ≈ {round(transform[0],4)} [{crs.linear_units}])')\n",
    "axes[1, 0].set_ylabel(f'Y-axis grids \\n(grid size ≈ {-round(transform[4],4)} [{crs.linear_units}])')\n",
    "cbar3 = fig.colorbar(im2, ax=axes[1, 0], orientation='horizontal', fraction=0.045, pad=0.13)\n",
    "\n",
    "# Plot the r-square\n",
    "im3 = axes[1, 1].imshow(r2_result, cmap='coolwarm_r')\n",
    "im3.set_clim(0, round(np.nanpercentile(r2_result, 100), 2))\n",
    "axes[1, 1].set_title('Coefficient of determination (R$^{2}$)')\n",
    "axes[1, 1].set_xlabel(f'X-axis grids \\n(grid size ≈ {round(transform[0],4)} [{crs.linear_units}])')\n",
    "axes[1, 1].set_ylabel(f'Y-axis grids \\n(grid size ≈ {-round(transform[4],4)} [{crs.linear_units}])')\n",
    "cbar4 = fig.colorbar(im3, ax=axes[1, 1], orientation='horizontal', fraction=0.045, pad=0.13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pyfracd.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
